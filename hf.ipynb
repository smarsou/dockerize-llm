{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/huggingface/huggingface_hub/issues/36#issuecomment-1619942423\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "from huggingface_hub import get_hf_file_metadata, hf_hub_url, repo_info\n",
    "from huggingface_hub.utils import EntryNotFoundError, RepositoryNotFoundError, RevisionNotFoundError\n",
    "\n",
    "\n",
    "def repo_exists(repo_id: str, repo_type: Optional[str] = None, token: Optional[str] = None) -> bool:\n",
    "    try:\n",
    "        res = repo_info(repo_id, repo_type=repo_type, token=token)\n",
    "        return True\n",
    "    except RepositoryNotFoundError:\n",
    "        return False\n",
    "\n",
    "def file_exists(\n",
    "    repo_id: str,\n",
    "    filename: str,\n",
    "    repo_type: Optional[str] = None,\n",
    "    revision: Optional[str] = None,\n",
    "    token: Optional[str] = None,\n",
    ") -> bool:\n",
    "    url = hf_hub_url(repo_id=repo_id, repo_type=repo_type, revision=revision, filename=filename)\n",
    "    try:\n",
    "        get_hf_file_metadata(url, token=token)\n",
    "        return True\n",
    "    except (RepositoryNotFoundError, EntryNotFoundError, RevisionNotFoundError):\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "def download_file():\n",
    "    hf_hub_download(repo_id=\"tiiuae/falcon-7b-instruct\", filename=\"config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "GatedRepoError",
     "evalue": "401 Client Error. (Request ID: Root=1-662e8654-7ea813ac3caba3442418c968;04123d8f-6eca-46c8-868f-8918e5219aeb)\n\nCannot access gated repo for url https://huggingface.co/api/models/google/codegemma-7b.\nAccess to model google/codegemma-7b is restricted. You must be authenticated to access it.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Freelance/dockerized_llm/env/lib/python3.11/site-packages/huggingface_hub/utils/_errors.py:304\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Freelance/dockerized_llm/env/lib/python3.11/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://huggingface.co/api/models/google/codegemma-7b",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mGatedRepoError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrepo_info\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[38;5;124;43mgoogle/codegemma-7b\u001b[39;49m\u001b[38;5;124;43m\"\"\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Freelance/dockerized_llm/env/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:119\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    117\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Freelance/dockerized_llm/env/lib/python3.11/site-packages/huggingface_hub/hf_api.py:2418\u001b[0m, in \u001b[0;36mHfApi.repo_info\u001b[0;34m(self, repo_id, revision, repo_type, timeout, files_metadata, token)\u001b[0m\n\u001b[1;32m   2416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2417\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported repo type.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2418\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2419\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiles_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2424\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Freelance/dockerized_llm/env/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:119\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    117\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 119\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Freelance/dockerized_llm/env/lib/python3.11/site-packages/huggingface_hub/hf_api.py:2228\u001b[0m, in \u001b[0;36mHfApi.model_info\u001b[0;34m(self, repo_id, revision, timeout, securityStatus, files_metadata, token)\u001b[0m\n\u001b[1;32m   2226\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblobs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   2227\u001b[0m r \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mget(path, headers\u001b[38;5;241m=\u001b[39mheaders, timeout\u001b[38;5;241m=\u001b[39mtimeout, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m-> 2228\u001b[0m \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2229\u001b[0m data \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m   2230\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ModelInfo(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdata)\n",
      "File \u001b[0;32m~/Freelance/dockerized_llm/env/lib/python3.11/site-packages/huggingface_hub/utils/_errors.py:321\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGatedRepo\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    318\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot access gated repo for url \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m     )\n\u001b[0;32m--> 321\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GatedRepoError(message, response) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_message \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccess to this resource is disabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    324\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    325\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Client Error.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccess to this resource is disabled.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    330\u001b[0m     )\n",
      "\u001b[0;31mGatedRepoError\u001b[0m: 401 Client Error. (Request ID: Root=1-662e8654-7ea813ac3caba3442418c968;04123d8f-6eca-46c8-868f-8918e5219aeb)\n\nCannot access gated repo for url https://huggingface.co/api/models/google/codegemma-7b.\nAccess to model google/codegemma-7b is restricted. You must be authenticated to access it."
     ]
    }
   ],
   "source": [
    "repo_info(\"\"\"google/codegemma-7b\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "model_name = \"codellama/CodeLlama-7b-hf\"\n",
    "url = f'https://huggingface.co/api/models/{model_name}'\n",
    "res = requests.get(url)\n",
    "\n",
    "res.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': '64e78d117acd8971f2c6bbe6', 'id': 'TheBloke/CodeLlama-7B-GGUF', 'likes': 97, 'likes7d': 1, 'private': False, 'downloads': 6649, 'tags': ['transformers', 'gguf', 'llama', 'llama-2', 'text-generation', 'code', 'arxiv:2308.12950', 'base_model:codellama/CodeLlama-7b-hf', 'license:llama2', 'has_space', 'text-generation-inference', 'region:us'], 'pipeline_tag': 'text-generation', 'library_name': 'transformers', 'createdAt': '2023-08-24T17:02:09.000Z', 'modelId': 'TheBloke/CodeLlama-7B-GGUF'}\n",
      "{'_id': '64e78cdac3b2443fb30b9dda', 'id': 'TheBloke/CodeLlama-7B-Instruct-GGUF', 'likes': 106, 'likes7d': 0, 'private': False, 'downloads': 42004, 'tags': ['transformers', 'gguf', 'llama', 'llama-2', 'text-generation', 'code', 'arxiv:2308.12950', 'base_model:codellama/CodeLlama-7b-instruct-hf', 'license:llama2', 'has_space', 'text-generation-inference', 'region:us'], 'pipeline_tag': 'text-generation', 'library_name': 'transformers', 'createdAt': '2023-08-24T17:01:14.000Z', 'modelId': 'TheBloke/CodeLlama-7B-Instruct-GGUF'}\n",
      "{'_id': '64e78d0b1703da9e63ecc64c', 'id': 'TheBloke/CodeLlama-7B-Python-GGUF', 'likes': 49, 'likes7d': 0, 'private': False, 'downloads': 4152, 'tags': ['transformers', 'gguf', 'llama', 'llama-2', 'text-generation', 'code', 'arxiv:2308.12950', 'base_model:codellama/CodeLlama-7b-python-hf', 'license:llama2', 'text-generation-inference', 'region:us'], 'pipeline_tag': 'text-generation', 'library_name': 'transformers', 'createdAt': '2023-08-24T17:02:03.000Z', 'modelId': 'TheBloke/CodeLlama-7B-Python-GGUF'}\n",
      "{'_id': '64f7f3a7a92703ef65da130c', 'id': 'rizerphe/CodeLlama-function-calling-6320-7b-Instruct-GGUF', 'likes': 7, 'likes7d': 0, 'private': False, 'downloads': 0, 'tags': ['dataset:rizerphe/glaive-function-calling-v2-llama', 'dataset:rizerphe/sharegpt-hyperfiltered-3k-llama', 'dataset:totally-not-an-llm/sharegpt-hyperfiltered-3k', 'dataset:glaiveai/glaive-function-calling-v2', 'license:llama2', 'region:us'], 'createdAt': '2023-09-06T03:36:07.000Z', 'modelId': 'rizerphe/CodeLlama-function-calling-6320-7b-Instruct-GGUF'}\n",
      "{'_id': '6512c16ec456f50350e03a12', 'id': 's3nh/frankminors123-Chinese-CodeLlama-7B-PT-GGUF', 'likes': 0, 'likes7d': 0, 'private': False, 'downloads': 140, 'tags': ['transformers', 'gguf', 'text-generation', 'zh', 'en', 'license:openrail', 'endpoints_compatible', 'region:us'], 'pipeline_tag': 'text-generation', 'library_name': 'transformers', 'createdAt': '2023-09-26T11:33:02.000Z', 'modelId': 's3nh/frankminors123-Chinese-CodeLlama-7B-PT-GGUF'}\n",
      "{'_id': '651a23068da5a69248e7cfd8', 'id': 'Nexesenex/Codellama-2-7b-Miniguanaco-Mistral-GGUF', 'likes': 3, 'likes7d': 0, 'private': False, 'downloads': 462, 'tags': ['gguf', 'license:llama2', 'region:us'], 'createdAt': '2023-10-02T01:55:18.000Z', 'modelId': 'Nexesenex/Codellama-2-7b-Miniguanaco-Mistral-GGUF'}\n",
      "{'_id': '6526ecef62da6eaddc60f700', 'id': 'adamo1139/PS_AD_O365_CodeLlama_7B_05_QLoRA_GGUF', 'likes': 0, 'likes7d': 0, 'private': False, 'downloads': 9, 'tags': ['gguf', 'license:llama2', 'region:us'], 'createdAt': '2023-10-11T18:43:59.000Z', 'modelId': 'adamo1139/PS_AD_O365_CodeLlama_7B_05_QLoRA_GGUF'}\n",
      "{'_id': '652b4f91a2d97e682b3c6c74', 'id': 'alphahg/CodeLlama-7b-hf-rust-finetune-GGUF', 'likes': 0, 'likes7d': 0, 'private': False, 'downloads': 38, 'tags': ['gguf', 'generated_from_trainer', 'base_model:codellama/CodeLlama-7b-hf', 'license:llama2', 'region:us'], 'createdAt': '2023-10-15T02:33:53.000Z', 'modelId': 'alphahg/CodeLlama-7b-hf-rust-finetune-GGUF'}\n",
      "{'_id': '654a92b57f0fd3f2548ce410', 'id': 'support-pvelocity/Code-Llama-2-7B-instruct-text2sql-GGUF', 'likes': 0, 'likes7d': 0, 'private': False, 'downloads': 44, 'tags': ['gguf', 'text-generation', 'en', 'license:llama2', 'region:us'], 'pipeline_tag': 'text-generation', 'createdAt': '2023-11-07T19:40:37.000Z', 'modelId': 'support-pvelocity/Code-Llama-2-7B-instruct-text2sql-GGUF'}\n",
      "{'_id': '655192f919c62ea90f604546', 'id': 'Vasanth/copilot-codellama-7b.gguf', 'likes': 2, 'likes7d': 0, 'private': False, 'downloads': 74, 'tags': ['gguf', 'region:us'], 'createdAt': '2023-11-13T03:07:37.000Z', 'modelId': 'Vasanth/copilot-codellama-7b.gguf'}\n",
      "{'_id': '65544e08f284ba421a541f2c', 'id': 'abneraigc/CodeLlama-7b-Instruct-hf-finetune_text2sql_ggml-f16.gguf', 'likes': 0, 'likes7d': 0, 'private': False, 'downloads': 302, 'tags': ['gguf', 'region:us'], 'createdAt': '2023-11-15T04:50:16.000Z', 'modelId': 'abneraigc/CodeLlama-7b-Instruct-hf-finetune_text2sql_ggml-f16.gguf'}\n",
      "{'_id': '65545341198da1df586797ed', 'id': 'abneraigc/CodeLlama-7b-Instruct-hf-finetune_text2sql-ggml-q5_k_m.gguf', 'likes': 1, 'likes7d': 0, 'private': False, 'downloads': 19, 'tags': ['gguf', 'region:us'], 'createdAt': '2023-11-15T05:12:33.000Z', 'modelId': 'abneraigc/CodeLlama-7b-Instruct-hf-finetune_text2sql-ggml-q5_k_m.gguf'}\n",
      "{'_id': '655493f05e88eda4382b5f57', 'id': 'mmnga/ELYZA-japanese-CodeLlama-7b-instruct-gguf', 'likes': 7, 'likes7d': 0, 'private': False, 'downloads': 764, 'tags': ['gguf', 'llama2', 'ja', 'arxiv:2308.12950', 'arxiv:2307.09288', 'license:llama2', 'region:us'], 'createdAt': '2023-11-15T09:48:32.000Z', 'modelId': 'mmnga/ELYZA-japanese-CodeLlama-7b-instruct-gguf'}\n",
      "{'_id': '65549526920f57435e2700ea', 'id': 'mmnga/ELYZA-japanese-CodeLlama-7b-gguf', 'likes': 0, 'likes7d': 0, 'private': False, 'downloads': 383, 'tags': ['gguf', 'llama2', 'ja', 'arxiv:2308.12950', 'arxiv:2307.09288', 'license:llama2', 'region:us'], 'createdAt': '2023-11-15T09:53:42.000Z', 'modelId': 'mmnga/ELYZA-japanese-CodeLlama-7b-gguf'}\n",
      "{'_id': '6566eab3e1604b205891c025', 'id': 'damerajee/copilot-codellama-q8-7b.gguf', 'likes': 0, 'likes7d': 0, 'private': False, 'downloads': 14, 'tags': ['gguf', 'region:us'], 'createdAt': '2023-11-29T07:39:31.000Z', 'modelId': 'damerajee/copilot-codellama-q8-7b.gguf'}\n",
      "{'_id': '656709992146168ad7d472bf', 'id': 'damerajee/copilot-codellama-q5-7b.gguf', 'likes': 0, 'likes7d': 0, 'private': False, 'downloads': 22, 'tags': ['gguf', 'region:us'], 'createdAt': '2023-11-29T09:51:21.000Z', 'modelId': 'damerajee/copilot-codellama-q5-7b.gguf'}\n",
      "{'_id': '65672d2d589e2122840eea76', 'id': 'damerajee/codellama-q5-7b.gguf', 'likes': 0, 'likes7d': 0, 'private': False, 'downloads': 7, 'tags': ['gguf', 'region:us'], 'createdAt': '2023-11-29T12:23:09.000Z', 'modelId': 'damerajee/codellama-q5-7b.gguf'}\n",
      "{'_id': '657b1c17ff16eeb2ee1c4924', 'id': 'ChiaH/codellama-ft-7b-v1.0-gguf', 'likes': 0, 'likes7d': 0, 'private': False, 'downloads': 14, 'tags': ['transformers', 'gguf', 'llama', 'endpoints_compatible', 'text-generation-inference', 'region:us'], 'library_name': 'transformers', 'createdAt': '2023-12-14T15:15:35.000Z', 'modelId': 'ChiaH/codellama-ft-7b-v1.0-gguf'}\n",
      "{'_id': '659ee2c7c4a3b8af42ab2a96', 'id': 'optimalworker/codellama-7b-instruct.Q6_K_gguf', 'likes': 0, 'likes7d': 0, 'private': False, 'downloads': 0, 'tags': ['license:mit', 'region:us'], 'createdAt': '2024-01-10T18:32:39.000Z', 'modelId': 'optimalworker/codellama-7b-instruct.Q6_K_gguf'}\n",
      "{'_id': '65b8109abaf43750574bc63a', 'id': 'macadeliccc/CodeLlama-7b-Python-hf-GGUF', 'likes': 0, 'likes7d': 0, 'private': False, 'downloads': 382, 'tags': ['gguf', 'region:us'], 'createdAt': '2024-01-29T20:54:50.000Z', 'modelId': 'macadeliccc/CodeLlama-7b-Python-hf-GGUF'}\n",
      "{'_id': '65e818fa1649b1896f090ae7', 'id': 'SinpxAI/CodeLlama-7B-Instruct-GGUF', 'likes': 0, 'likes7d': 0, 'private': False, 'downloads': 229, 'tags': ['transformers', 'gguf', 'llama', 'endpoints_compatible', 'text-generation-inference', 'region:us'], 'library_name': 'transformers', 'createdAt': '2024-03-06T07:19:22.000Z', 'modelId': 'SinpxAI/CodeLlama-7B-Instruct-GGUF'}\n",
      "{'_id': '65e83718f8c69953a807c76c', 'id': 'SinpxAI/CodeLlama-7B-GGUF', 'likes': 0, 'likes7d': 0, 'private': False, 'downloads': 208, 'tags': ['transformers', 'gguf', 'llama', 'endpoints_compatible', 'text-generation-inference', 'region:us'], 'library_name': 'transformers', 'createdAt': '2024-03-06T09:27:52.000Z', 'modelId': 'SinpxAI/CodeLlama-7B-GGUF'}\n",
      "{'_id': '65e856c3ded393e4f40566b3', 'id': 'SinpxAI/CodeLlama-7B-Python-GGUF', 'likes': 0, 'likes7d': 0, 'private': False, 'downloads': 326, 'tags': ['transformers', 'gguf', 'llama', 'endpoints_compatible', 'text-generation-inference', 'region:us'], 'library_name': 'transformers', 'createdAt': '2024-03-06T11:42:59.000Z', 'modelId': 'SinpxAI/CodeLlama-7B-Python-GGUF'}\n",
      "{'_id': '65eb09094b38d749ff33d274', 'id': 'PhilKey/codellama-7b-openrewrite-instruct-gguf', 'likes': 0, 'likes7d': 0, 'private': False, 'downloads': 0, 'tags': ['region:us'], 'createdAt': '2024-03-08T12:48:09.000Z', 'modelId': 'PhilKey/codellama-7b-openrewrite-instruct-gguf'}\n",
      "{'_id': '65f3270fca62dc6705d3ff11', 'id': 'qnixsynapse/CodeLlama-7B-Instruct-GGUF', 'likes': 0, 'likes7d': 0, 'private': False, 'downloads': 12, 'tags': ['gguf', 'en', 'license:llama2', 'region:us'], 'createdAt': '2024-03-14T16:34:23.000Z', 'modelId': 'qnixsynapse/CodeLlama-7B-Instruct-GGUF'}\n",
      "{'_id': '65f384a706ba21ca8f6f02b9', 'id': 'cosmo3769/CodeLlama-7b-hf-GGUF', 'likes': 0, 'likes7d': 0, 'private': False, 'downloads': 10, 'tags': ['gguf', 'region:us'], 'createdAt': '2024-03-14T23:13:43.000Z', 'modelId': 'cosmo3769/CodeLlama-7b-hf-GGUF'}\n",
      "{'_id': '65f9a87af4ce1b8cd5a145f1', 'id': 'arvnoodle/hcl-codellama-7b-instruct-javascript-lotuscript-GGUF', 'likes': 0, 'likes7d': 0, 'private': False, 'downloads': 84, 'tags': ['transformers', 'gguf', 'llama', 'text-generation-inference', 'unsloth', 'en', 'base_model:codellama/CodeLlama-7b-Instruct-hf', 'license:apache-2.0', 'endpoints_compatible', 'region:us'], 'library_name': 'transformers', 'createdAt': '2024-03-19T15:00:10.000Z', 'modelId': 'arvnoodle/hcl-codellama-7b-instruct-javascript-lotuscript-GGUF'}\n",
      "{'_id': '65fa0cc15475f53469ec266a', 'id': 'aless2212/CodeLlama-7b-Instruct-GGUF', 'likes': 0, 'likes7d': 0, 'private': False, 'downloads': 45, 'tags': ['gguf', 'license:apache-2.0', 'region:us'], 'createdAt': '2024-03-19T22:08:01.000Z', 'modelId': 'aless2212/CodeLlama-7b-Instruct-GGUF'}\n",
      "{'_id': '65fa15d23260327fc70ec17f', 'id': 'aless2212/CodeLlama-7b-Python-GGUF', 'likes': 0, 'likes7d': 0, 'private': False, 'downloads': 46, 'tags': ['gguf', 'license:apache-2.0', 'region:us'], 'createdAt': '2024-03-19T22:46:42.000Z', 'modelId': 'aless2212/CodeLlama-7b-Python-GGUF'}\n",
      "{'_id': '65fb090bd52e0bc6d23c4d48', 'id': 'PhilKey/codellama-7b-openrewrite-recipes-instruct-gguf', 'likes': 0, 'likes7d': 0, 'private': False, 'downloads': 0, 'tags': ['region:us'], 'createdAt': '2024-03-20T16:04:27.000Z', 'modelId': 'PhilKey/codellama-7b-openrewrite-recipes-instruct-gguf'}\n",
      "{'_id': '65fd8f328b87c6e3dd007ea1', 'id': 'mradermacher/CodeLlama-7b-CypherGen-GGUF', 'likes': 1, 'likes7d': 0, 'private': False, 'downloads': 190, 'tags': ['transformers', 'gguf', 'en', 'base_model:ozayezerceli/CodeLlama-7b-CypherGen', 'license:apache-2.0', 'endpoints_compatible', 'region:us'], 'library_name': 'transformers', 'createdAt': '2024-03-22T14:01:22.000Z', 'modelId': 'mradermacher/CodeLlama-7b-CypherGen-GGUF'}\n",
      "{'_id': '661225aa188ff298b0f3f6bb', 'id': 'QuantFactory/CodeLlama-7b-Instruct-hf-GGUF', 'likes': 0, 'likes7d': 0, 'private': False, 'downloads': 503, 'tags': ['transformers', 'gguf', 'code', 'llama', 'llama-2', 'text-generation-inference', 'text-generation', 'base_model:codellama/CodeLlama-7b-Instruct-hf', 'region:us'], 'pipeline_tag': 'text-generation', 'library_name': 'transformers', 'createdAt': '2024-04-07T04:48:42.000Z', 'modelId': 'QuantFactory/CodeLlama-7b-Instruct-hf-GGUF'}\n",
      "{'_id': '6612500e7554a7f1b7e16432', 'id': 'QuantFactory/CodeLlama-7b-hf-GGUF', 'likes': 0, 'likes7d': 0, 'private': False, 'downloads': 224, 'tags': ['transformers', 'gguf', 'text-generation-inference', 'llama', 'llama-2', 'code', 'text-generation', 'base_model:codellama/CodeLlama-7b-hf', 'region:us'], 'pipeline_tag': 'text-generation', 'library_name': 'transformers', 'createdAt': '2024-04-07T07:49:34.000Z', 'modelId': 'QuantFactory/CodeLlama-7b-hf-GGUF'}\n",
      "{'_id': '66238300ea4f4ed066283893', 'id': 'DavidAU/CodeLlama-7b-Instruct-hf-Q6_K-GGUF', 'likes': 0, 'likes7d': 0, 'private': False, 'downloads': 12, 'tags': ['gguf', 'llama-2', 'llama-cpp', 'gguf-my-repo', 'text-generation', 'code', 'license:llama2', 'region:us'], 'pipeline_tag': 'text-generation', 'createdAt': '2024-04-20T08:55:28.000Z', 'modelId': 'DavidAU/CodeLlama-7b-Instruct-hf-Q6_K-GGUF'}\n",
      "{'_id': '6624f0b9478dada130524d61', 'id': 'RichardErkhov/meta-llama_-_CodeLlama-7b-hf-gguf', 'likes': 0, 'likes7d': 0, 'private': False, 'downloads': 5199, 'tags': ['gguf', 'arxiv:2308.12950', 'region:us'], 'createdAt': '2024-04-21T10:55:53.000Z', 'modelId': 'RichardErkhov/meta-llama_-_CodeLlama-7b-hf-gguf'}\n",
      "{'_id': '6624f7c011772517e5e4ab5b', 'id': 'RichardErkhov/meta-llama_-_CodeLlama-7b-Python-hf-gguf', 'likes': 0, 'likes7d': 0, 'private': False, 'downloads': 5236, 'tags': ['gguf', 'arxiv:2308.12950', 'region:us'], 'createdAt': '2024-04-21T11:25:52.000Z', 'modelId': 'RichardErkhov/meta-llama_-_CodeLlama-7b-Python-hf-gguf'}\n",
      "{'_id': '662509c0c13bf768184d3eab', 'id': 'RichardErkhov/meta-llama_-_CodeLlama-7b-Instruct-hf-gguf', 'likes': 0, 'likes7d': 0, 'private': False, 'downloads': 5222, 'tags': ['gguf', 'arxiv:2308.12950', 'region:us'], 'createdAt': '2024-04-21T12:42:40.000Z', 'modelId': 'RichardErkhov/meta-llama_-_CodeLlama-7b-Instruct-hf-gguf'}\n",
      "{'_id': '662b93a389f38fd9ceb369a4', 'id': 'bravemindai/codellama-7b-transitional-services-beta-gguf', 'likes': 0, 'likes7d': 0, 'private': False, 'downloads': 1, 'tags': ['gguf', 'region:us'], 'createdAt': '2024-04-26T11:44:35.000Z', 'modelId': 'bravemindai/codellama-7b-transitional-services-beta-gguf'}\n",
      "{'_id': '662e36d8fb47bb27b03a3ada', 'id': 'OllmOne/CodeLlama-7B-Instruct-GGUF', 'likes': 0, 'likes7d': 0, 'private': False, 'downloads': 0, 'tags': ['gguf', 'license:llama2', 'region:us'], 'createdAt': '2024-04-28T11:45:28.000Z', 'modelId': 'OllmOne/CodeLlama-7B-Instruct-GGUF'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def search_repo(text, tag=None):\n",
    "    out = []\n",
    "    url = f'https://huggingface.co/api/models?search={text}'\n",
    "    res = requests.get(url)\n",
    "    for model in res.json():\n",
    "        print(model)\n",
    "\n",
    "def check_if_repo_is_gguf():\n",
    "    pass\n",
    "\n",
    "search_repo(\"codellama-7b gguf\")\n",
    "def list_gguf_in_repo(repo_id):\n",
    "    for file in repo_info(repo_id).siblings:\n",
    "        if re.match(\"^.*.gguf$\",file.rfilename):\n",
    "            print(file.rfilename)\n",
    "\n",
    "# list_gguf_in_repo(\"TheBloke/CodeLlama-7B-GGUF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"RichardErkhov/openai-community_-_gpt2-medium-gguf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "The `notebook_login` function can only be used in a notebook (Jupyter or Colab) and you need the `ipywidgets` module: `pip install ipywidgets`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/Freelance/dockerized_llm/env/lib/python3.11/site-packages/huggingface_hub/_login.py:237\u001b[0m, in \u001b[0;36mnotebook_login\u001b[0;34m(new_session, write_permission)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mipywidgets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mwidgets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mwidgets\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ipywidgets'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[64], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhuggingface_hub\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m login\n\u001b[0;32m----> 2\u001b[0m \u001b[43mlogin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Freelance/dockerized_llm/env/lib/python3.11/site-packages/huggingface_hub/_login.py:112\u001b[0m, in \u001b[0;36mlogin\u001b[0;34m(token, add_to_git_credential, new_session, write_permission)\u001b[0m\n\u001b[1;32m    110\u001b[0m     _login(token, add_to_git_credential\u001b[38;5;241m=\u001b[39madd_to_git_credential, write_permission\u001b[38;5;241m=\u001b[39mwrite_permission)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_notebook():\n\u001b[0;32m--> 112\u001b[0m     \u001b[43mnotebook_login\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_session\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrite_permission\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwrite_permission\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    114\u001b[0m     interpreter_login(new_session\u001b[38;5;241m=\u001b[39mnew_session, write_permission\u001b[38;5;241m=\u001b[39mwrite_permission)\n",
      "File \u001b[0;32m~/Freelance/dockerized_llm/env/lib/python3.11/site-packages/huggingface_hub/_login.py:240\u001b[0m, in \u001b[0;36mnotebook_login\u001b[0;34m(new_session, write_permission)\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m--> 240\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `notebook_login` function can only be used in a notebook (Jupyter or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Colab) and you need the `ipywidgets` module: `pip install ipywidgets`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m     )\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m new_session \u001b[38;5;129;01mand\u001b[39;00m _current_token_okay(write_permission\u001b[38;5;241m=\u001b[39mwrite_permission):\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser is already logged in.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: The `notebook_login` function can only be used in a notebook (Jupyter or Colab) and you need the `ipywidgets` module: `pip install ipywidgets`."
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
