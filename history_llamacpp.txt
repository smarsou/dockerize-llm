1  apt update
    2  apt install git
    3  cd /root/
    4  ls
    5  git clone https://github.com/ggerganov/llama.cpp
    6  cd llama.cpp/
    7  make
    8  ls
    9  apt install make
   10  make
   11  apt install build-essential
   12  make
   13  apt install -y ccache
   14  make
   15  /usr/sbin/update-ccache-symlinks
   16  /usr/sbin/update-ccache-symlinks 
   17  echo 'export PATH="/usr/lib/ccache:$PATH"' | tee -a ~/.bashrc
   18  tee
   19  source ~/.bashrc && echo $PATH
   20  make
   21  make LLAMA_DEBUG=1
   22  pip install -r llama.cpp/requirements.txt
   23  apt-get install python3.10
   24  apt-get install python3
   25  python3 -m pip install -r llama.cpp/requirements.txt
   26  python3 --version
   27  apt install python3-pip
   28  pip3 --version
   29  pip 
   30  pip install -r llama.cpp/requirements.txt
   31  python3 -m pip
   32  python3 -m pip install
   33  python3 -m pip install requirements.txt 
   34  apt install python3-xyz
   35  cat requirements
   36  cat requirements.txt 
   37  pip install -r requirements.txt
   38  pip install -r requirements.txt --break-system-packages
   39  ls
   40  make LLAMA_DEBUG=1
   41  ls
   42  apt install wget
   43  wget https://huggingface.co/RichardErkhov/openai-community_-_gpt2-medium-gguf/resolve/main/gpt2-medium.Q6_K.gguf?download=true
   44  ls
   45  cd ..
   46  ls
   47  cd llama.cpp/
   48  ls models/
   49  cd models/
   50  wget https://huggingface.co/RichardErkhov/openai-community_-_gpt2-medium-gguf/resolve/main/gpt2-medium.Q6_K.gguf?download=true
   51  ls
   52  cd ..
   53  ls
   54  ls models/
   55  mv models/gpt2-medium.Q6_K.gguf\?download\=true  models/gpt2.gguf
   56  ls models/
   57  ls
   58  ls
   59  pip install 'llama-cpp-python[server]'
   60  pip install 'llama-cpp-python[server]' --break-system-packages
   61  top
   62  fg
   63  python3 -m llama_cpp.server --model models/gpt2.gguf 
   64  export MODELS=./models/gpt2.gguf HOST=0.0.0.0 PORT=2600
   65  python3 -m llama_cpp.server --model models/gpt2.gguf 
   66  curl http://localhost:2600/v1/models -H 'Content-Type: application/json'
   67  apt install curl
   68  curl http://localhost:2600/v1/models -H 'Content-Type: application/json'
   69  fg
   70  bg
   71  curl http://localhost:2600/v1/models -H 'Content-Type: application/json'
   72  clea
   73  curl http://localhost:2600/v1/models -H 'Content-Type: application/json'
   74  curl http://localhost:2600/v1/chat/completions -H 'Content-Type: application/json' -d '{{\"model\": \"models/gpt2.gguf\", \"messages\": [{{\"role\": \"user\", \"content\": \"Are you loaded ?\"}}], \"temperature\": 0.9}}'
   75  clear
   76  curl http://localhost:2600/v1/chat/completions -H 'Content-Type: application/json' -d '{{\"model\": \"models/gpt2.gguf\", \"messages\": [{"role": "user", "content": "Are you loaded ?"}], "temperature": 0.9}'
   77  clear
   78  curl http://localhost:2600/v1/chat/completions -H 'Content-Type: application/json' -d '{\"model\": \"models/gpt2.gguf\", \"messages\": [{\"role\": \"user\", \"content\": \"Are you loaded ?\"}], \"temperature\": 0.9}'
   79  curl http://localhost:2600/v1/chat/completions -H 'Content-Type: application/json' -d '{"model": "models/gpt2.gguf", "messages": [{"role": "user", "content": "Are you loaded ?"}], "temperature": 0.9}'
   80  ls
   81  ls
   82  fg
   83  ls
   84  history